{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12002,"status":"ok","timestamp":1655587341587,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"QFZAWeQzlYDG","outputId":"bc712004-7b6e-4e1b-e65e-3673451dfc70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.14.6)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (1.26.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (13.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.1.2)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.9.2)\n","Requirement already satisfied: aiohttp in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.8.6)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.17.3)\n","Requirement already satisfied: packaging in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: colorama in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# install hugging face datasets module\n","%pip install datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9072,"status":"ok","timestamp":1655587409671,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"O8Egk4utk--s","outputId":"ec7d8f19-f814-4134-d3dc-f18e099da748"},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.34.1)\n","Requirement already satisfied: filelock in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2023.10.3)\n","Requirement already satisfied: requests in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n","Requirement already satisfied: colorama in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["# install transformers library\n","%pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9023,"status":"ok","timestamp":1655587426734,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"KiLRpLEfmxqM"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Ben\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# import necessary packages\n","import transformers, pandas as pd\n","from datasets import Dataset, load_metric\n","import numpy as np\n","from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, AutoModelForSequenceClassification, Trainer"]},{"cell_type":"markdown","metadata":{"id":"ZaF59TvWsQI8"},"source":["### Prepare the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1655587435898,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"BH2OXp2YjT7F"},"outputs":[],"source":["# create the sample emails texts\n","sample_mails = [\"I will share your email\",\n","\"I shall share your email\",\n","\"I've shared your email\",\n","\"May I share your email\",\n","\"Should I share your email\",\n","\"I already shared the email\",\n","\"I've just shared your email\",\n","\"Am I allowed to share your email\",\n","\"Am I able to share your email\",\n","\"I am able to share your email\",\n","\"Will you help my friends if I share your email with them?\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1655587437694,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"D_c1iidVjoSS"},"outputs":[],"source":["# manually create a label match for each sample mail\n","mail_labels = [\"Student wants to know if can share\",\n","\"Student wants to know if can share\",\n","\"Student has shared\",\n","\"Student wants to know if can share\",\n","\"Student wants to know if can share\",\n","\"Student has shared\",\n","\"Student has shared\",\n","\"Student wants to know if can share\",\n","\"Student wants to know if can share\",\n","\"Student has shared\",\n","\"Student wants to know if can share\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1655587468013,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"nuQB_BJhoLRl","outputId":"e3890f25-acb9-42e7-a0f1-2192b1739298"},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax. Perhaps you forgot a comma? (368758319.py, line 2)","output_type":"error","traceback":["\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.read_csv(Training Data.csv)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"]}],"source":["# load dataset as pandas Dataframe\n","df = pd.DataFrame({'sample_mails': sample_mails, 'labels': mail_labels})\n","\n","# check\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1655587493109,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"19mTVz2rrrqP","outputId":"f447a33a-c8e4-455e-d645-d1f9c36e0d2d"},"outputs":[{"data":{"text/plain":["datasets.arrow_dataset.Dataset"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# load the dataframe in a hugging face compatible format\n","dataset = Dataset.from_pandas(df)\n","\n","# check the type\n","type(dataset)"]},{"cell_type":"markdown","metadata":{"id":"AbFltOF2uvIk"},"source":["### Preprocessing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["0d8302ca67134193a10ade69c44041bf","89e96f9fcfed418895ef4887072b134d","c6b02c2d616f41af9ded54c7916709ee","b88ce659f6f4451eb43bf7bd6610f0d6","30b853bfac2d4eafafa5208e914aa40e","5fe39bf5c8d446dc8dc9aa86429b7423","bf060a5ee51b458aa6517a3bf503e59b","a2505a274ff243589f05bf088c1e0992","36c4eb53fb1f40f9bd232c59979d52db","f9214a7b86334b92b3df3f3389cf154e","7202ebce10d943f5885631fc36418058","f954762c305c4be9ae3fd2682e7efe53","459c48905efe477cb25c5eb8dc3c0571","27549b8720c741199e42b55049ac1c1f","10ef2c11a1754e708834372100e6eb5b","b7032e7ea083403d9abf038b48c328e5","fe8e0db9a7ce4810974b58c0f7fb9ff4","840f26b2aa4640b4919625d9504df3f6","823582762af34fa3b85ab758fc06d8a3","df7418fee5f34b0584500f63aaa480eb","c1cf39a62d064404920f5dbc2175829e","d1d37f46d21e476b80319fb3143055ff"]},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1655570875322,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"dNNz2rv70Yfj","outputId":"339a52c1-ebd4-4a4c-82f6-c101a7213eb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Casting to class labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 430.71 examples/s]\n"]}],"source":["# encode the dataset labels as integers\n","dataset = dataset.class_encode_column('labels')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1655570875323,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"cH03nZ8OqJOx","outputId":"182d1a02-e701-4e42-bb32-5d19048df666"},"outputs":[{"data":{"text/plain":["{'sample_mails': \"I've shared your email\", 'labels': 0}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# view a sample of the dataset\n","dataset[2]"]},{"cell_type":"markdown","metadata":{"id":"XH34IgbA-sd3"},"source":["From the above output, we see that label `0` indicates the label `Student has shared` therefore label `1` will indicate `Student wants to know if can share`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1655570875324,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"_0RBElLCxqnZ","outputId":"4ec48573-84b6-46fa-bbee-bb737aaa8b81"},"outputs":[{"data":{"text/plain":["{'sample_mails': Value(dtype='string', id=None),\n"," 'labels': ClassLabel(names=['Student has shared', 'Student wants to know if can share'], id=None)}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# verify the dataset features\n","dataset.features"]},{"cell_type":"markdown","metadata":{"id":"nRpuYrIwNF6-"},"source":["### Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1370,"status":"ok","timestamp":1655570876647,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"J-fs0RpU0BAU"},"outputs":[],"source":["# declare the checkpoint\n","checkpoint = \"bert-base-uncased\"\n","\n","# call the tokenizer for training\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":85,"status":"ok","timestamp":1655570876656,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"wqsctMTmlB22"},"outputs":[],"source":["# create a function for tokenizing the sample_mails\n","def tokenize_function(example):\n","    return tokenizer(example[\"sample_mails\"], truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["fa5f86eee50443969a0cd33309bd7127","faed0052fe0c461095f078464b9dc55c","c72399c3c7ab4781b423a60ba393b5e3","4a4884cabad94a83b0fac2c12b0574e5","df6ea8d5f4764b738c8539fdbf5f47cb","f1b50327eed54763b244185ab211cacf","00d76b58b434493abaea93735bd876d8","19bf2c0fa8c347ec84635386dba59ab5","a39c3c5ee7d24900a6c2fe359c4261d2","3c095e7707b04738952a5b4483b496b5","24c73ce427214973bde836688b2700c7"]},"executionInfo":{"elapsed":89,"status":"ok","timestamp":1655570876666,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"agGQC2dnPxNU","outputId":"d9631022-a6bd-48c6-b8df-d102b8a2c843"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 275.02 examples/s]\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['sample_mails', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 11\n","})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# tokenize the dataset with the map function\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","tokenized_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":78,"status":"ok","timestamp":1655570876671,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"KBRzYe8fnE6h"},"outputs":[],"source":["# apply dynamic padding -- pad all the sample_mails to the length of the longest element when we batch elements together\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"NqjYk8U2nx1L"},"source":["To test this new toy, we'll slice our dataset that we would like to batch together. Here, we remove the columns idx and sample_mails as they wonâ€™t be needed and contain strings (and we canâ€™t create tensors with strings) and have a look at the lengths of each entry in the batch:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75,"status":"ok","timestamp":1655570876672,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"80WVTJEynF6D","outputId":"0eab2d28-f044-45d2-a81a-46e3ea3ea189"},"outputs":[{"data":{"text/plain":["[7, 7, 8, 7, 7, 7, 9, 9, 9, 9, 15]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["samples = tokenized_datasets[:]\n","samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sample_mails\"]}\n","[len(x) for x in samples[\"input_ids\"]]"]},{"cell_type":"markdown","metadata":{"id":"nOXm9aNApFMv"},"source":["No surprise, we get samples of varying length, from 7 to 15. Dynamic padding means the samples in this batch should all be padded to a length of 15, the maximum length inside the batch. Without dynamic padding, all of the samples would have to be padded to the maximum length in the whole dataset, or the maximum length the model can accept. Letâ€™s double-check that our data_collator is dynamically padding the batch properly:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1655570876677,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"y0UZkLubom6z","outputId":"2bcf63ae-25c8-4089-8cf0-37d695abe045"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/plain":["{'labels': torch.Size([11]),\n"," 'input_ids': torch.Size([11, 15]),\n"," 'token_type_ids': torch.Size([11, 15]),\n"," 'attention_mask': torch.Size([11, 15])}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["batch = data_collator(samples)\n","{k: v.shape for k, v in batch.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1655570876678,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"MC4YYdKlVHVy","outputId":"21097335-efa3-4a10-adbb-81d94a7e8977"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# check if we're using a fast tokenizer\n","tokenizer.is_fast"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1655570876680,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"_lf3AFOQPyC_","outputId":"7fd91539-1f64-4510-9ffa-5b22a67c19e2"},"outputs":[{"data":{"text/plain":["['[CLS]',\n"," 'will',\n"," 'you',\n"," 'help',\n"," 'my',\n"," 'friends',\n"," 'if',\n"," 'i',\n"," 'share',\n"," 'your',\n"," 'email',\n"," 'with',\n"," 'them',\n"," '?',\n"," '[SEP]']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# we can convert the tokenized dataset back to text as follows\n","tokenizer.convert_ids_to_tokens(tokenized_datasets['input_ids'][-1])"]},{"cell_type":"markdown","metadata":{"id":"Bq1iZSRTZjRC"},"source":["### Training\n","\n","The first step before we can define our Trainer is to define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, in our case we want to also modify the number of epochs for training,  the checkpoints along the way are also saved in this directory. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":453,"status":"ok","timestamp":1655570877090,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"FK6WKUMWt5gX"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Ben\\AppData\\Local\\Temp\\ipykernel_732\\3420635880.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n"]}],"source":["# define a metric to monitor during training\n","metric = load_metric(\"accuracy\")\n","\n","# create a function that helps compute the specified metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1655570877091,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"cqIKniIhUtgk"},"outputs":[],"source":["# define the training arguments\n","training_args = TrainingArguments('training_args',\n","                                  num_train_epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"tQgo27OMac5X"},"source":["The second step is to define our model. We will use the AutoModelForSequenceClassification class, with two labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3789,"status":"ok","timestamp":1655570880876,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"k2Qv5h4CacDc","outputId":"548e794a-b9ae-4b7a-b23b-cf6de50c7080"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [01:00<00:00, 7.34MB/s] \n","C:\\Users\\Ben\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ben\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"]},{"cell_type":"markdown","metadata":{"id":"pwPBV42gbgh2"},"source":["You will notice that you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6773,"status":"ok","timestamp":1655570887603,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"L9o69w-IbADb"},"outputs":[],"source":["# define trainer object\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"markdown","metadata":{"id":"1rMR-jXpdMXu"},"source":["To fine-tune the model on our dataset, we just have to call the train() method of our Trainer:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":3466,"status":"ok","timestamp":1655570890961,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"_T110yLucf_o","outputId":"45866c2d-396b-4659-d9f7-61bce14d2223"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [02:53<00:00,  4.33s/it]"]},{"name":"stdout","output_type":"stream","text":["{'train_runtime': 172.9928, 'train_samples_per_second': 1.272, 'train_steps_per_second': 0.231, 'train_loss': 0.24077908992767333, 'epoch': 20.0}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["TrainOutput(global_step=40, training_loss=0.24077908992767333, metrics={'train_runtime': 172.9928, 'train_samples_per_second': 1.272, 'train_steps_per_second': 0.231, 'train_loss': 0.24077908992767333, 'epoch': 20.0})"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1802,"status":"ok","timestamp":1655570892698,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"vZjIBUq7fUUQ","outputId":"d8e99315-5a81-4daf-9d11-324363ef2ce1"},"outputs":[],"source":["# save the trained model together with the tokenizer in a directory\n","trainer.save_model('custom_model')"]},{"cell_type":"markdown","metadata":{"id":"cWaWym99zcUg"},"source":["### Evaluation\n","\n","For this task, we will evaluate the model on the training set, given that the dataset is extremely small and could not be split into train-test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1655570892717,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"Nkl5dLmwgYST","outputId":"9bbe2b92-cd08-4298-950c-be4b768618ce"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.90it/s]"]},{"name":"stdout","output_type":"stream","text":["(11, 2) (11,) \n","\n","PredictionOutput(predictions=array([[-1.9196216,  1.3245827],\n","       [-1.949448 ,  1.3339628],\n","       [ 1.7652345, -1.1058381],\n","       [-2.0256405,  1.362749 ],\n","       [-2.0248377,  1.3859997],\n","       [ 1.6743466, -1.0574694],\n","       [ 1.7554849, -1.0992212],\n","       [-2.0404794,  1.3920761],\n","       [-1.9952593,  1.3621099],\n","       [ 1.7081995, -1.0845065],\n","       [-2.0348525,  1.3852504]], dtype=float32), label_ids=array([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1], dtype=int64), metrics={'test_loss': 0.04296018183231354, 'test_accuracy': 1.0, 'test_runtime': 1.6477, 'test_samples_per_second': 6.676, 'test_steps_per_second': 1.214})\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["predictions = trainer.predict(tokenized_datasets)\n","print(predictions.predictions.shape, predictions.label_ids.shape, '\\n')\n","print(predictions)"]},{"cell_type":"markdown","metadata":{"id":"hS1xBv2f3oM-"},"source":["The output of the `predict()` method is another named tuple with three fields: predictions, `label_ids`, and `metrics`. The metrics field now contains the loss on the dataset passed, some time metrics (how long it took to predict, in total and on average), and the accuracy of training\n","\n","As we can see, predictions is a two-dimensional array with shape 11 x 2 (11 being the number of elements in the dataset we used). Those are the logits for each element of the dataset we passed to `predict()`. To transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1655570892720,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"tWrsESYHqtgm"},"outputs":[],"source":["preds = np.argmax(predictions.predictions, axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"NxjkyUq-6VVA"},"source":["We can now compare those preds to the labels. To build our `compute_metric()` function, we will rely on the metrics from the ðŸ¤— Datasets library. We can load the metrics associated with the MRPC dataset as easily as we loaded the dataset, this time with the `load_metric()` function. The object returned has a `compute()` method we can use to do the metric calculation. Wrapping everything together, we get our `compute_metrics_mrpc()` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655570893158,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"xpiiHNIM882M"},"outputs":[],"source":["def compute_metrics_mrpc(eval_preds):\n","    metric = load_metric(\"glue\", \"mrpc\")\n","    logits, labels = eval_preds.predictions, eval_preds.label_ids\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1655570893515,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"gGs9IY4m-G-I","outputId":"19c64b2f-8a60-4917-92e2-061864b3abcc"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading builder script: 5.76kB [00:00, ?B/s]                       \n"]},{"data":{"text/plain":["{'accuracy': 1.0, 'f1': 1.0}"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["compute_metrics_mrpc(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1655570893516,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"9Sn6-O-p-dDr","outputId":"b28619c3-deb4-463e-96f3-ff62f9abcbf5"},"outputs":[{"data":{"text/plain":["array([[-1.9196216,  1.3245827],\n","       [-1.949448 ,  1.3339628],\n","       [ 1.7652345, -1.1058381],\n","       [-2.0256405,  1.362749 ],\n","       [-2.0248377,  1.3859997],\n","       [ 1.6743466, -1.0574694],\n","       [ 1.7554849, -1.0992212],\n","       [-2.0404794,  1.3920761],\n","       [-1.9952593,  1.3621099],\n","       [ 1.7081995, -1.0845065],\n","       [-2.0348525,  1.3852504]], dtype=float32)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["predictions.predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1655570893518,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"KQH9c_mv-NeE","outputId":"c2ca3852-e68f-49cd-dee2-6571731daad8"},"outputs":[{"data":{"text/plain":["array([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1], dtype=int64)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["predictions.label_ids"]},{"cell_type":"markdown","metadata":{"id":"9FRTXK4zu14Q"},"source":["From the above, we see that the model has a perfect prediction on the data it was trained on. This is highly flawed and can be ascribed to overfitting, but since we have no test set to evaluate on given the size of the sample data, we can assume that for the model to overfit at 20 epochs, it actually did well in learning the training dataset.\n","\n","### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2223,"status":"ok","timestamp":1655573150063,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"LZI4lSsd_6Up","outputId":"00bd1179-48de-4dbb-c68d-7acfaae6fda8"},"outputs":[],"source":["# get the directory where the model was saved to\n","inf_model = AutoModelForSequenceClassification.from_pretrained('custom_model/')"]},{"cell_type":"markdown","metadata":{},"source":["I had to change the path of the custom model to 'custom_model/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1655573338250,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"IB80F5BT2W5r","outputId":"f4e87cc7-c38b-40d7-d376-6899aee91d52"},"outputs":[],"source":["# load the tokenizer by pointing to the same directory as the pretrained model\n","inf_tokenizer = AutoTokenizer.from_pretrained('custom_model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1655575117312,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"2hCuCbqM23CI"},"outputs":[],"source":["# generate sequence for inference\n","sequences = ['I want to know if I should send your email', 'I sent your email a long time ago']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":809,"status":"ok","timestamp":1655574094394,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"vLVXPplE3xxl"},"outputs":[],"source":["# create a pipeline for inference\n","from transformers import pipeline\n","classifier = pipeline(task='text-classification', model=inf_model, tokenizer=inf_tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1655575120730,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"UgGbs7b65FDU","outputId":"d05c6a45-a20a-4995-edca-62da3f48d494"},"outputs":[{"data":{"text/plain":["[{'label': 'LABEL_1', 'score': 0.9348370432853699},\n"," {'label': 'LABEL_0', 'score': 0.7933637499809265}]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["classifier(sequences)"]},{"cell_type":"markdown","metadata":{"id":"EJxapWpg7hlG"},"source":["From the above output, we can confidently say the model is performing well on inference"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMu8uMKYqRgHJuCZ6XQuSiq","collapsed_sections":[],"mount_file_id":"1pZMgEIulV3c4SiuhbryXmdfF9-YkUv86","name":"train_model.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00d76b58b434493abaea93735bd876d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d8302ca67134193a10ade69c44041bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89e96f9fcfed418895ef4887072b134d","IPY_MODEL_c6b02c2d616f41af9ded54c7916709ee","IPY_MODEL_b88ce659f6f4451eb43bf7bd6610f0d6"],"layout":"IPY_MODEL_30b853bfac2d4eafafa5208e914aa40e"}},"10ef2c11a1754e708834372100e6eb5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1cf39a62d064404920f5dbc2175829e","placeholder":"â€‹","style":"IPY_MODEL_d1d37f46d21e476b80319fb3143055ff","value":" 1/1 [00:00&lt;00:00, 17.49ba/s]"}},"19bf2c0fa8c347ec84635386dba59ab5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24c73ce427214973bde836688b2700c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27549b8720c741199e42b55049ac1c1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_823582762af34fa3b85ab758fc06d8a3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df7418fee5f34b0584500f63aaa480eb","value":1}},"30b853bfac2d4eafafa5208e914aa40e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c4eb53fb1f40f9bd232c59979d52db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c095e7707b04738952a5b4483b496b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"459c48905efe477cb25c5eb8dc3c0571":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe8e0db9a7ce4810974b58c0f7fb9ff4","placeholder":"â€‹","style":"IPY_MODEL_840f26b2aa4640b4919625d9504df3f6","value":"Casting the dataset: 100%"}},"4a4884cabad94a83b0fac2c12b0574e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c095e7707b04738952a5b4483b496b5","placeholder":"â€‹","style":"IPY_MODEL_24c73ce427214973bde836688b2700c7","value":" 1/1 [00:00&lt;00:00, 11.43ba/s]"}},"5fe39bf5c8d446dc8dc9aa86429b7423":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7202ebce10d943f5885631fc36418058":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"823582762af34fa3b85ab758fc06d8a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840f26b2aa4640b4919625d9504df3f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89e96f9fcfed418895ef4887072b134d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fe39bf5c8d446dc8dc9aa86429b7423","placeholder":"â€‹","style":"IPY_MODEL_bf060a5ee51b458aa6517a3bf503e59b","value":"Casting to class labels: 100%"}},"a2505a274ff243589f05bf088c1e0992":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a39c3c5ee7d24900a6c2fe359c4261d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7032e7ea083403d9abf038b48c328e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b88ce659f6f4451eb43bf7bd6610f0d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9214a7b86334b92b3df3f3389cf154e","placeholder":"â€‹","style":"IPY_MODEL_7202ebce10d943f5885631fc36418058","value":" 1/1 [00:00&lt;00:00, 24.78ba/s]"}},"bf060a5ee51b458aa6517a3bf503e59b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1cf39a62d064404920f5dbc2175829e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b02c2d616f41af9ded54c7916709ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2505a274ff243589f05bf088c1e0992","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36c4eb53fb1f40f9bd232c59979d52db","value":1}},"c72399c3c7ab4781b423a60ba393b5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19bf2c0fa8c347ec84635386dba59ab5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a39c3c5ee7d24900a6c2fe359c4261d2","value":1}},"d1d37f46d21e476b80319fb3143055ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df6ea8d5f4764b738c8539fdbf5f47cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df7418fee5f34b0584500f63aaa480eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1b50327eed54763b244185ab211cacf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9214a7b86334b92b3df3f3389cf154e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f954762c305c4be9ae3fd2682e7efe53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_459c48905efe477cb25c5eb8dc3c0571","IPY_MODEL_27549b8720c741199e42b55049ac1c1f","IPY_MODEL_10ef2c11a1754e708834372100e6eb5b"],"layout":"IPY_MODEL_b7032e7ea083403d9abf038b48c328e5"}},"fa5f86eee50443969a0cd33309bd7127":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_faed0052fe0c461095f078464b9dc55c","IPY_MODEL_c72399c3c7ab4781b423a60ba393b5e3","IPY_MODEL_4a4884cabad94a83b0fac2c12b0574e5"],"layout":"IPY_MODEL_df6ea8d5f4764b738c8539fdbf5f47cb"}},"faed0052fe0c461095f078464b9dc55c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1b50327eed54763b244185ab211cacf","placeholder":"â€‹","style":"IPY_MODEL_00d76b58b434493abaea93735bd876d8","value":"100%"}},"fe8e0db9a7ce4810974b58c0f7fb9ff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
